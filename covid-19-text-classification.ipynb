{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1472453,"sourceType":"datasetVersion","datasetId":863934}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bcodep06/covid-19-text-classification?scriptVersionId=260837692\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# COVID-19 Tweet Sentiment Classification\n\nThis notebook performs text classification on COVID-19 related tweets. The steps include:\n1. Data Loading\n2. Preprocessing (cleaning, mentions, hashtags, compound words, lemmatization)\n3. Train/Test Split\n4. TF-IDF Vectorization\n5. Label Encoding\n6. Model Training with Logistic Regression\n7. Evaluation on Training and Test Sets","metadata":{"_uuid":"edb448c3-1f2d-46c3-9a7c-d047165e1ca3","_cell_guid":"fbdac08f-9cb3-4a3a-a9d1-7df1ae93dde1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pip install -U scikit-learn imbalanced-learn","metadata":{"_uuid":"55428f8f-8b18-441c-a8a5-a120038edd89","_cell_guid":"c1b6f39d-8cf6-418d-a462-7cba75c8fca8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T12:19:24.235813Z","iopub.execute_input":"2025-09-09T12:19:24.236175Z","iopub.status.idle":"2025-09-09T12:19:24.240962Z","shell.execute_reply.started":"2025-09-09T12:19:24.23615Z","shell.execute_reply":"2025-09-09T12:19:24.239989Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import required libraries\nimport numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC","metadata":{"_uuid":"add2cd21-3ee0-4ce1-ac50-97b2fd99f299","_cell_guid":"795073f6-23e1-4a5b-bc93-78cd22c567ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:24.242815Z","iopub.execute_input":"2025-09-09T12:19:24.24321Z","iopub.status.idle":"2025-09-09T12:19:24.259182Z","shell.execute_reply.started":"2025-09-09T12:19:24.243176Z","shell.execute_reply":"2025-09-09T12:19:24.258172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Load Dataset","metadata":{"_uuid":"9eb64ccd-f53b-4fdb-98ca-e26757ce8c5a","_cell_guid":"2266fcce-964b-49cd-a4ca-aba2614fac7c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load CSV dataset\ndf = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding = 'latin1')\n\n# Select relevant columns\ntext_data = df.iloc[:, -2:]\ntext_data.head(8)","metadata":{"_uuid":"32bb404c-29b5-4caf-810c-62b906ef5068","_cell_guid":"ee5716f7-de1e-41c0-a8fc-dd924ecee335","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:24.260064Z","iopub.execute_input":"2025-09-09T12:19:24.260395Z","iopub.status.idle":"2025-09-09T12:19:24.479846Z","shell.execute_reply.started":"2025-09-09T12:19:24.260374Z","shell.execute_reply":"2025-09-09T12:19:24.478678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking imbalance\nprint(text_data['Sentiment'].value_counts())","metadata":{"_uuid":"a8a24e4f-8f44-4164-8dd7-2c620dd60ef0","_cell_guid":"f294835e-2b89-4ed4-8eb0-f6d82c1e2fcb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T12:19:24.480709Z","iopub.execute_input":"2025-09-09T12:19:24.480981Z","iopub.status.idle":"2025-09-09T12:19:24.49027Z","shell.execute_reply.started":"2025-09-09T12:19:24.48096Z","shell.execute_reply":"2025-09-09T12:19:24.489311Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Text Preprocessing","metadata":{"_uuid":"fbfe3f3a-d1f6-4d1c-bc97-fc666324e0b2","_cell_guid":"4e468d19-a9eb-42e8-b9d9-12f9ec987b88","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Initialize lemmatizer\nlemmatizer = WordNetLemmatizer()\n\n# List of known keywords to help split compound words in hashtags or concatenated words\nKEYWORDS = ['coronavirus', 'vaccine', 'lockdown', 'outbreak', 'airline', 'webcheckin']\n\n# Function to split compound words using known keywords\ndef split_compound_words(text):\n    for kw in KEYWORDS:\n        text = re.sub(f'({kw})([a-z]+)', r'\\1 \\2', text)\n    return text\n\ndef text_preprocessing(text):\n    # Convert all text to lowercase to standardize words\n    text = text.lower()\n\n    # Remove words followed by a colon\n    text = re.sub(r'\\w+:','', text)\n    # Remove hashtags symbol (#) but keep the word following it\n    text = re.sub(r'#(\\w+)', r'\\1', text)\n    # Split known compound words in hashtags or concatenated words (like 'coronavirusoutbreak')\n    text = split_compound_words(text)\n    # Replace all mentions (@username) with a placeholder 'MENTION'\n    text = re.sub(r'@\\w+', 'MENTION', text)\n    # Remove URLs and links from the text\n    text = re.sub(r'https\\S+|www\\S+|\\/\\/t\\.co/\\S+', '', text)\n    # Remove any text inside parentheses\n    text = re.sub(r'\\([^)]*\\)','', text)\n    # Replace all numbers with a placeholder '<NUM>'\n    text = re.sub(r'\\d+', ' <NUM> ', text)\n    # Remove punctuation characters to simplify text\n    text = re.sub(r'[.,!?;:&$|=]', ' ', text)\n    # Replace multiple spaces with a single space and remove leading/trailing spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n\n\n    # Lemmatize each token\n    tokens = word_tokenize(text)\n    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n    text = ' '.join(tokens)\n    \n    return text\n\n# Apply preprocessing\ntext_data['CleanedTweet'] = text_data['OriginalTweet'].apply(text_preprocessing)","metadata":{"_uuid":"909df8fa-67e5-45af-9025-75c569e2c6f3","_cell_guid":"d33c6402-1b73-434f-ac17-63fe7e765af3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:24.492558Z","iopub.execute_input":"2025-09-09T12:19:24.492884Z","iopub.status.idle":"2025-09-09T12:19:38.655999Z","shell.execute_reply.started":"2025-09-09T12:19:24.492861Z","shell.execute_reply":"2025-09-09T12:19:38.655197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Train/Test Split","metadata":{"_uuid":"b7817331-b368-4254-b37f-3aa77d92f110","_cell_guid":"de76ab13-55db-4c96-92b9-a6408d3bba58","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"X = text_data['CleanedTweet']\ny = text_data['Sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)","metadata":{"_uuid":"2072651d-ae74-4389-84d2-376e37644f2b","_cell_guid":"0daaa01c-261f-494a-9b13-8df5218bb4aa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:38.657041Z","iopub.execute_input":"2025-09-09T12:19:38.657444Z","iopub.status.idle":"2025-09-09T12:19:38.7122Z","shell.execute_reply.started":"2025-09-09T12:19:38.65741Z","shell.execute_reply":"2025-09-09T12:19:38.711193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Label Encoding","metadata":{"_uuid":"87787fc8-c737-4525-b7fd-74bc40ab6a35","_cell_guid":"6fa6a786-288b-4007-8a38-c5715ff571f0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"le = LabelEncoder()\ny_train_enc = le.fit_transform(y_train)\ny_test_enc = le.transform(y_test)","metadata":{"_uuid":"45a8f2e5-83a8-470e-a292-014089ec4db1","_cell_guid":"2a315114-c4d9-49a5-9da3-5b4c32cb4265","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:38.713439Z","iopub.execute_input":"2025-09-09T12:19:38.713742Z","iopub.status.idle":"2025-09-09T12:19:38.727622Z","shell.execute_reply.started":"2025-09-09T12:19:38.713719Z","shell.execute_reply":"2025-09-09T12:19:38.726769Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. TF-IDF Vectorization","metadata":{"_uuid":"8cdebb86-3dfc-4e82-9179-f8b1b0b253a9","_cell_guid":"37d2be38-af93-4ead-bbf3-d33c20a55a39","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(\n    stop_words='english',\n    ngram_range=(1,2),\n    max_features=3000,\n    min_df=3,\n    max_df=0.85\n)\n\n\nX_train_vec = tfidf.fit_transform(X_train)\nX_test_vec = tfidf.transform(X_test)","metadata":{"_uuid":"09c6013a-ec19-4219-a0ab-12cbcfcadc6f","_cell_guid":"355d5b35-4bdc-4a76-aef4-8bbf4c6abcea","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:38.728754Z","iopub.execute_input":"2025-09-09T12:19:38.729109Z","iopub.status.idle":"2025-09-09T12:19:41.722748Z","shell.execute_reply.started":"2025-09-09T12:19:38.729081Z","shell.execute_reply":"2025-09-09T12:19:41.721741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Optional: Inspect features of a sample tweet","metadata":{"_uuid":"950081c5-65ea-45fb-9b37-550d2783bde4","_cell_guid":"ba6d1607-38ce-46cf-933a-045202a93088","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"feature_names = tfidf.get_feature_names_out()\nfirst_row = X_train_vec[3].toarray()[0]\nnon_zero_indices = first_row.nonzero()[0]\n\nfor idx in non_zero_indices:\n    print(feature_names[idx], first_row[idx])","metadata":{"_uuid":"5f762510-b347-4439-9783-73d7abfea2ac","_cell_guid":"e6c9ce68-466c-4bb5-ae67-fc53683e6dee","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:41.723776Z","iopub.execute_input":"2025-09-09T12:19:41.724066Z","iopub.status.idle":"2025-09-09T12:19:41.734673Z","shell.execute_reply.started":"2025-09-09T12:19:41.724045Z","shell.execute_reply":"2025-09-09T12:19:41.733432Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Train Logistic Regression Model","metadata":{"_uuid":"8fc5272b-450c-442b-944e-ea3d91ae11cb","_cell_guid":"b1ab9ff6-9a89-4356-a7bb-d28aebaeddc6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nros = RandomOverSampler(random_state=42)\nX_train_res, y_train_res = ros.fit_resample(X_train_vec, y_train_enc)","metadata":{"_uuid":"11652d22-7543-4cae-949e-d2712d1caa05","_cell_guid":"4dd6d0e9-18d0-40e6-b3ed-fa5c8785492b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T12:19:41.735882Z","iopub.execute_input":"2025-09-09T12:19:41.736145Z","iopub.status.idle":"2025-09-09T12:19:41.770476Z","shell.execute_reply.started":"2025-09-09T12:19:41.736125Z","shell.execute_reply":"2025-09-09T12:19:41.769587Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\n# Applying TruncatedSVD for dimensionality reduction\nsvd = TruncatedSVD(n_components=400, random_state=42)\nX_train_vec_svd = svd.fit_transform(X_train_res)\nX_test_vec_svd = svd.transform(X_test_vec)","metadata":{"_uuid":"6be39b0d-5ca6-4ebf-98ce-7934e26252ef","_cell_guid":"e9050fc6-88a6-464e-b829-e82dfe816fa1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T12:19:41.771405Z","iopub.execute_input":"2025-09-09T12:19:41.771675Z","iopub.status.idle":"2025-09-09T12:19:53.271419Z","shell.execute_reply.started":"2025-09-09T12:19:41.771654Z","shell.execute_reply":"2025-09-09T12:19:53.270623Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\nmodels = {\n    'LogisticRegression': LogisticRegression(C = 0.5,max_iter=1000, class_weight='balanced',solver='lbfgs',random_state=42),\n    'Naive Bayes': MultinomialNB(),\n    'Linear SVC': LinearSVC(C = 0.5,class_weight='balanced', random_state=42)\n}\n\nfor label, model in models.items():\n    print(f\"\\nTraining Model With {label}....\")\n\n    if label == \"Naive Bayes\":\n        model.fit(X_train_vec, y_train_enc)\n        y_pred = model.predict(X_test_vec)\n    else:\n        model.fit(X_train_vec_svd, y_train_res)\n        y_pred = model.predict(X_test_vec_svd)\n\n    print(f\"\\nResults for {label}:\")\n    print(classification_report(y_test_enc, y_pred, target_names=le.classes_))\n    print(f\"Balanced Accuracy ({label}):\", balanced_accuracy_score(y_test_enc, y_pred))\n\n","metadata":{"_uuid":"bf07eaa9-d3a7-4000-a0af-2bedecf31480","_cell_guid":"ecde5963-9102-43bf-8f97-062393bed57f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:19:53.272237Z","iopub.execute_input":"2025-09-09T12:19:53.27251Z","iopub.status.idle":"2025-09-09T12:23:22.854042Z","shell.execute_reply.started":"2025-09-09T12:19:53.272486Z","shell.execute_reply":"2025-09-09T12:23:22.852897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Evaluate Model","metadata":{"_uuid":"fbcafb1c-1029-4400-810e-ba100ec7e02f","_cell_guid":"dd3e1283-0240-4b0f-9c10-3d43e042b9f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.5, 1, 2, 5]}\ngrid = GridSearchCV(LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42),\n                    param_grid, cv=3, scoring='balanced_accuracy', n_jobs=-1)\ngrid.fit(X_train_vec, y_train_enc)\nprint(\"Best Params:\", grid.best_params_)\nprint(\"Best Score:\", grid.best_score_)\n","metadata":{"_uuid":"1322a211-4919-45e2-a105-68d8762ae593","_cell_guid":"d8c138b9-f2df-4984-9e49-71c733c3e270","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T12:25:06.53267Z","iopub.execute_input":"2025-09-09T12:25:06.533485Z","iopub.status.idle":"2025-09-09T12:25:24.039746Z","shell.execute_reply.started":"2025-09-09T12:25:06.533451Z","shell.execute_reply":"2025-09-09T12:25:24.038669Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Retrain final model with C=5","metadata":{}},{"cell_type":"code","source":"final_model = LogisticRegression(C=5, max_iter=2000, class_weight='balanced', random_state=42)\nfinal_model.fit(X_train_vec, y_train_enc)\ny_pred = final_model.predict(X_test_vec)\n\nprint(classification_report(y_test_enc, y_pred, target_names=le.classes_))\nprint(\"Balanced Accuracy:\", balanced_accuracy_score(y_test_enc, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T12:26:58.797645Z","iopub.execute_input":"2025-09-09T12:26:58.798001Z","iopub.status.idle":"2025-09-09T12:27:04.535666Z","shell.execute_reply.started":"2025-09-09T12:26:58.797977Z","shell.execute_reply":"2025-09-09T12:27:04.534202Z"}},"outputs":[],"execution_count":null}]}